{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "BfjRsV5Snwlx",
    "outputId": "009529c0-5728-41b2-b470-9c17963506ef"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib import autograph as ag\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xCVTtoo84lo8"
   },
   "source": [
    "\n",
    "# **Defining our input and output data**\n",
    "\n",
    "MNIST images have a dimension of 28 * 28 pixels with one color channel. Our inputs _Xin will be batches of MNIST characters, while our network will learn to reconstruct them and output them in a placeholder Y, which thus has the same dimensions. _Yflat will be used later, when computing losses. _keepprob will be used when applying dropouts as a means of regularization. During training, it will have a value of 0.8. When generating new data, we won't apply dropout, so the value will be 1. The function lrelu is being defined as tensorflow unfortunately doesn't come up with a predefined leaky ReLU.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9Cx6iEwn3Jv"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 64\n",
    "dec_in_channels = 1\n",
    "n_latent = 8\n",
    "\n",
    "X_in = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='X')\n",
    "Z_in = tf.placeholder(dtype=tf.float32, shape=[None, n_latent], name = 'Z')\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name='keep_prob')\n",
    "\n",
    "# Only used in VAE\n",
    "\n",
    "# Y    = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28], name='Y')\n",
    "# mean = tf.placeholder(dtype=tf.float32, shape=[None, n_latent], name = 'mean')\n",
    "# std = tf.placeholder(dtype=tf.float32, shape=[None, n_latent], name = 'std')\n",
    "# Y_flat = tf.reshape(Y, shape=[-1, 28 * 28])\n",
    "\n",
    "reshaped_dim = [-1, 7, 7, dec_in_channels]\n",
    "inputs_decoder = np.floor(7 * 7 * dec_in_channels / 2)\n",
    "\n",
    "def lrelu(x, alpha=0.3):\n",
    "    return tf.maximum(x, tf.multiply(x, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaix-Mdt5Ja_"
   },
   "source": [
    "\n",
    "# **Defining the encoder**\n",
    "\n",
    "As our inputs are images, it's most reasonable to apply some convolutional transformations to them. What's most noteworthy is the fact that we are creating two vectors in our encoder, as the encoder is supposed to create objects following a Gaussian Distribution:\n",
    "\n",
    "*   A vector of means\n",
    "*   A vector of standard deviations\n",
    "\n",
    "You will see later how we \"force\" the encoder to make sure it really creates values following a Normal Distribution. The returned values that will be fed to the decoder are the z-values. We will need the mean and standard deviation of our distributions later, when computing losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw1lHAllsfLN"
   },
   "outputs": [],
   "source": [
    "def encoder(X_in, keep_prob):\n",
    "    activation = lrelu\n",
    "    with tf.variable_scope(\"encoder\", reuse=None):\n",
    "        X = tf.reshape(X_in, shape=[-1, 28, 28, 1])\n",
    "        x = tf.layers.conv2d(X, \n",
    "                             filters=64, \n",
    "                             kernel_size=4, \n",
    "                             strides=2, \n",
    "                             padding='same', \n",
    "                             activation=activation)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(x, \n",
    "                             filters=64, \n",
    "                             kernel_size=4, \n",
    "                             strides=2, \n",
    "                             padding='same', \n",
    "                             activation=activation)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d(x, \n",
    "                             filters=64, \n",
    "                             kernel_size=4, \n",
    "                             strides=1, \n",
    "                             padding='same', \n",
    "                             activation=activation)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        \n",
    "        mean = tf.layers.dense(x, units=n_latent)\n",
    "        std = 0.5 * tf.layers.dense(x, units=n_latent)            \n",
    "        epsilon = tf.random_normal(tf.stack([tf.shape(x)[0], n_latent])) \n",
    "        z  = mean + tf.multiply(epsilon, tf.exp(std))\n",
    "        \n",
    "        return z, mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lxqk9_Fg1Pz3"
   },
   "source": [
    "# **Interpolation**\n",
    "For any two latent vectors, we can compute the difference between them to find out evenly spaced interpolates. If we assume there exist two latent vectors $L1$ and $L2$, then the interpolate $L_n$ can be computed by:\n",
    "\n",
    "\n",
    ">  $L_n = L1 + \\frac{n}{N}(L2 - L1)$\n",
    "\n",
    "where $N$ is the total number of spaces and $n$ is the $n_{th}$ segment along the vector $L2-L1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxcAn9pwEM9p"
   },
   "source": [
    "# **Defining the decoder**\n",
    "The decoder does not care about whether the input values are sampled from some specific distribution that has been defined by us. It simply will try to reconstruct the input images. To this end, we use a series of transpose convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzsk1GivwYR3"
   },
   "outputs": [],
   "source": [
    "def decoder(Z_in, keep_prob):\n",
    "    with tf.variable_scope(\"decoder\", reuse=None):\n",
    "        x = tf.layers.dense(Z_in, units=inputs_decoder, activation=lrelu)\n",
    "        x = tf.layers.dense(x, units=inputs_decoder * 2 + 1, activation=lrelu)\n",
    "        x = tf.reshape(x, reshaped_dim)\n",
    "        x = tf.layers.conv2d_transpose(x, \n",
    "                                       filters=64, \n",
    "                                       kernel_size=4, \n",
    "                                       strides=2, \n",
    "                                       padding='same', \n",
    "                                       activation=tf.nn.relu)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d_transpose(x, \n",
    "                                       filters=64, \n",
    "                                       kernel_size=4, \n",
    "                                       strides=1, \n",
    "                                       padding='same', \n",
    "                                       activation=tf.nn.relu)\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        x = tf.layers.conv2d_transpose(x, \n",
    "                                       filters=64, \n",
    "                                       kernel_size=4, \n",
    "                                       strides=1, \n",
    "                                       padding='same', \n",
    "                                       activation=tf.nn.relu)       \n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, units=28*28, activation=tf.nn.sigmoid)\n",
    "        img = tf.reshape(x, shape=[-1, 28, 28])\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(D_in):\n",
    "    with tf.variable_scope(\"discriminator\", reuse=None):\n",
    "        x = tf.contrib.layers.flatten(D_in)\n",
    "        x = tf.layers.dense(x, units=512, activation=activation)\n",
    "        x = tf.layers.dense(x, units=256, activation=activation)\n",
    "        d = tf.layers.dense(x, units=1, activation=tf.nn.sigmoid)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same(digit, labels):\n",
    "    idx = np.where(digit == labels)\n",
    "    rand_idx = np.random.choice(idx[0], 2, False)\n",
    "    return rand_idx[0], rand_idx[1]\n",
    "\n",
    "def different(digit, labels):\n",
    "    idx = np.where(digit == labels)\n",
    "    rand_idx1 = np.random.choice(idx[0], 1, False)\n",
    "    idx = np.where(digit != labels)\n",
    "    rand_idx2 = np.random.choice(idx[0], 1, False)\n",
    "    return rand_idx1[0], rand_idx2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "AxYqyFI9ISoN",
    "outputId": "15da0458-ce1a-41b9-8c32-b72eec14cacb"
   },
   "outputs": [],
   "source": [
    "sampled_z, mn, sd = encoder(X_in, keep_prob)\n",
    "dec = decoder(Z_in, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RB2RdgL8xwfL"
   },
   "outputs": [],
   "source": [
    "# VAE loss\n",
    "\n",
    "# unreshaped = tf.reshape(dec, [-1, 28*28])\n",
    "# img_loss = tf.reduce_sum(tf.squared_difference(unreshaped, Y_flat), 1)\n",
    "# latent_loss = -0.5 * tf.reduce_sum(1.0 + 2.0 * std - tf.square(mean) - tf.exp(2.0 * std), 1)\n",
    "# loss = tf.reduce_mean(img_loss + latent_loss)\n",
    "# optimizer = tf.train.AdamOptimizer(0.0005).minimize(loss)\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16HN_Pgtw_Dc"
   },
   "outputs": [],
   "source": [
    "# VAE train\n",
    "\n",
    "# labels = mnist.test.labels\n",
    "# epochs = 30000\n",
    "# for i in range(epochs):\n",
    "#     batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]\n",
    "#     s_z, mu, sigma = sess.run([sampled_z, mn, sd], feed_dict = {X_in: batch, keep_prob: 0.8})\n",
    "#     sess.run(optimizer, feed_dict = {Z_in: s_z, mean: mu, std: sigma, Y: batch, keep_prob: 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE+GAN loss\n",
    "\n",
    "data_prob = discriminator(X_in)\n",
    "G_prob = discriminator(dec)\n",
    "D_loss = tf.reduce_sum(tf.log(data_prob) + tf.log(1-G_prob), 1)\n",
    "G_loss = tf.reduce_sum(tf.log(G_prob), 1)\n",
    "D_optimizer = tf.train.AdamOptimizer(0.0005).maximize(D_loss)\n",
    "G_optimizer = tf.train.AdamOptimizer(0.0005).maximize(G_loss)\n",
    "sess = tf.Session(tf.ConfigProto().gpu_option.allow_growth=True)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE+GAN train\n",
    "\n",
    "labels = mnist.test.labels\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    batch = [np.reshape(b, [28, 28]) for b in mnist.train.next_batch(batch_size=batch_size)[0]]\n",
    "    s_z, mu, sigma = sess.run([sampled_z, mn, sd], feed_dict = {X_in: batch, keep_prob: 0.8})\n",
    "    d = sess.run(dec, feed_dict = {Z_in: s_z, mean: mu, std: sigma, Y: batch, keep_prob: 0.8})\n",
    "    for k in range(3):\n",
    "        sess.run(D_optimizer, feed_dict = {X_in: batch, Z_in: d, keep_prob: 0.8})\n",
    "    sess.run(G_optimizer, feed_dict = {Z_in: d, keep_prob = 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit = np.random.choice(np.arange(10), 1, False)\n",
    "# # interpolate with same digit\n",
    "# idx1, idx2 = same(digit, labels)\n",
    "# img1 = np.reshape(mnist.test.images[idx1], (-1, 28, 28))\n",
    "# img2 = np.reshape(mnist.test.images[idx2], (-1, 28, 28))\n",
    "# s_z1, mu1, sigma1 = sess.run([sampled_z, mn, sd], feed_dict = {X_in: img1, keep_prob: 1})\n",
    "# s_z2, mu2, sigma2 = sess.run([sampled_z, mn, sd], feed_dict = {X_in: img2, keep_prob: 1})\n",
    "# diff = s_z1 - s_z2\n",
    "# plt.figure()\n",
    "# plt.imshow(np.reshape(img1, (28, 28)), cmap='gray')\n",
    "# for j in range(9):\n",
    "#     s_z = s_z1 + (j/8) * diff\n",
    "#     d, _ = sess.run([dec,optimizer], feed_dict = {Z_in: s_z, mean: mu1, std: sigma1, Y: img1, keep_prob: 1})\n",
    "#     plt.figure()\n",
    "#     plt.imshow(np.reshape(d, (28, 28)), cmap='gray')\n",
    "\n",
    "# # interpolate with different digit\n",
    "# idx1, idx2 = different(digit, labels)\n",
    "# img1 = np.reshape(mnist.test.images[idx1], (-1, 28, 28))\n",
    "# img2 = np.reshape(mnist.test.images[idx2], (-1, 28, 28))\n",
    "# s_z1, mu1, sigma1 = sess.run([sampled_z, mn, sd], feed_dict = {X_in: img1, keep_prob: 1})\n",
    "# s_z2, mu2, sigma2 = sess.run([sampled_z, mn, sd], feed_dict = {X_in: img2, keep_prob: 1})\n",
    "# diff = s_z1 - s_z2\n",
    "# plt.figure()\n",
    "# plt.imshow(np.reshape(img1, (28, 28)), cmap='gray')\n",
    "# for j in range(9):\n",
    "#     s_z = s_z1 + (j/8) * diff\n",
    "#     d, _ = sess.run([dec,optimizer], feed_dict = {Z_in: s_z, mean: mu1, std: sigma1, Y: img1, keep_prob: 1})\n",
    "#     plt.figure()\n",
    "#     plt.imshow(np.reshape(d, (28, 28)), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "VAE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
